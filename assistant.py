import pyaudio
import wave
import requests
import json
import subprocess
import anthropic
import google.generativeai as genai
from google.cloud import texttospeech
import struct
import math
import time
import os
import re
from difflib import SequenceMatcher
import pickle
from supabase import create_client
from mem0 import MemoryClient

# ============ Supabase ì„¤ì • ============
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

# ============ Mem0 ì„¤ì • ============
MEM0_API_KEY = os.getenv("MEM0_API_KEY")
MEM0_USER_ID = "junseok"
mem0_client = MemoryClient(api_key=MEM0_API_KEY)

# ìë™ íƒœê¹… ëŒ€ê¸° ìƒíƒœ
pending_tag_info = None

# ============ API ì„¤ì • ============
CLIENT_ID = os.getenv("RETURNZERO_CLIENT_ID")
CLIENT_SECRET = os.getenv("RETURNZERO_CLIENT_SECRET")
CLAUDE_API_KEY = os.getenv("ANTHROPIC_API_KEY")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "/home/dhwnstjr0/ai-assistant/google_tts_key.json"
genai.configure(api_key=GEMINI_API_KEY)

# ============ ì˜¤ë””ì˜¤ ì„¤ì • ============
CHUNK = 4096
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 44100
WAVE_FILE = "input.wav"
OUTPUT_FILE = "output.mp3"
SILENCE_THRESHOLD = 300
SILENCE_DURATION = 1.5

HISTORY_FILE = "/home/dhwnstjr0/ai-assistant/conversation_history.pkl"
MAX_HISTORY = 100

def load_history():
    try:
        with open(HISTORY_FILE, 'rb') as f:
            return pickle.load(f)
    except:
        return []

def save_history(history):
    with open(HISTORY_FILE, 'wb') as f:
        pickle.dump(history, f)

def load_from_supabase():
    try:
        response = supabase.table("conversations").select("role, content").order("created_at", desc=True).limit(10).execute()
        if response.data:
            conversations = list(reversed(response.data))
            return [{"role": c["role"], "content": c["content"]} for c in conversations]
    except Exception as e:
        print(f"Supabase ë¶ˆëŸ¬ì˜¤ê¸° ì˜¤ë¥˜: {e}")
    return []

def save_to_supabase(role, content):
    try:
        supabase.table("conversations").insert({
            "role": role,
            "content": content,
            "source": "raspberry"
        }).execute()
    except Exception as e:
        print(f"Supabase ì €ì¥ ì˜¤ë¥˜: {e}")

# ============ Mem0 í•¨ìˆ˜ë“¤ ============
def add_to_mem0(text):
    try:
        mem0_client.add(text, user_id=MEM0_USER_ID)
        print(f"ğŸ§  Mem0ì— ì €ì¥ë¨")
    except Exception as e:
        print(f"Mem0 ì €ì¥ ì˜¤ë¥˜: {e}")

def search_mem0(query):
    try:
        results = mem0_client.search(query, user_id=MEM0_USER_ID, filters={"user_id": MEM0_USER_ID})
        if results and results.get("results"):
            memories = [r["memory"] for r in results["results"][:5]]
            return memories
    except Exception as e:
        print(f"Mem0 ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
    return []

def get_all_mem0():
    try:
        results = mem0_client.get_all(user_id=MEM0_USER_ID)
        if results and results.get("results"):
            return [r["memory"] for r in results["results"]]
    except Exception as e:
        print(f"Mem0 ì „ì²´ ì¡°íšŒ ì˜¤ë¥˜: {e}")
    return []

# ì‹œì‘ ì‹œ Supabaseì—ì„œ ëŒ€í™” ë¶ˆëŸ¬ì˜¤ê¸°
print("ğŸ“¡ Supabaseì—ì„œ ëŒ€í™” ê¸°ë¡ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
conversation_history = load_from_supabase()
if conversation_history:
    print(f"âœ… ìµœê·¼ ëŒ€í™” {len(conversation_history)}ê°œ ë¶ˆëŸ¬ì˜´")
else:
    conversation_history = load_history()
    print("ğŸ“‚ ë¡œì»¬ ë°±ì—…ì—ì„œ ëŒ€í™” ë¶ˆëŸ¬ì˜´")

# ============ Supabase íƒœê·¸ í•¨ìˆ˜ë“¤ ============
def normalize_tag(tag):
    tag = tag.lower().replace(" ", "").replace(".", "")
    replacements = {
        "ì—ì´": "a", "ë¹„": "b", "ì”¨": "c", "ë””": "d", "ì´": "e",
        "ì—í”„": "f", "ì§€": "g", "ì—ì´ì¹˜": "h", "ì•„ì´": "i", "ì œì´": "j",
        "ì¼€ì´": "k", "ì—˜": "l", "ì— ": "m", "ì—”": "n", "ì˜¤": "o",
        "í”¼": "p", "í": "q", "ì•Œ": "r", "ì—ìŠ¤": "s", "í‹°": "t",
        "ìœ ": "u", "ë¸Œì´": "v", "ë”ë¸”ìœ ": "w", "ì—‘ìŠ¤": "x", "ì™€ì´": "y", "ì œíŠ¸": "z"
    }
    for kor, eng in replacements.items():
        tag = tag.replace(kor, eng)
    return tag

def get_all_tags():
    try:
        response = supabase.table("tags").select("tag_name").execute()
        if response.data:
            return list(set([item["tag_name"] for item in response.data]))
    except Exception as e:
        print(f"íƒœê·¸ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {e}")
    return []

def find_similar_tag(tag_name):
    tag_name = normalize_tag(tag_name)
    existing_tags = get_all_tags()
    for existing in existing_tags:
        existing_norm = normalize_tag(existing)
        if tag_name == existing_norm:
            return existing
        ratio = SequenceMatcher(None, tag_name, existing_norm).ratio()
        if ratio > 0.7:
            return existing
    return None

def save_to_tag(tag_name, content):
    similar = find_similar_tag(tag_name)
    if similar:
        tag_name = similar
    try:
        supabase.table("tags").insert({
            "tag_name": tag_name,
            "content": content if isinstance(content, str) else json.dumps(content, ensure_ascii=False)
        }).execute()
        print(f"âœ… '{tag_name}' íƒœê·¸ë¡œ ì €ì¥ë¨")
        return tag_name
    except Exception as e:
        print(f"íƒœê·¸ ì €ì¥ ì˜¤ë¥˜: {e}")
        return None

def search_tag(tag_name):
    similar = find_similar_tag(tag_name)
    if not similar:
        return None, []
    try:
        response = supabase.table("tags").select("*").eq("tag_name", similar).order("created_at", desc=True).execute()
        return similar, response.data if response.data else []
    except Exception as e:
        print(f"íƒœê·¸ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return similar, []

def get_tag_context(question):
    keywords = {
        "ì—¬ìì¹œêµ¬": ["ì—¬ìì¹œêµ¬", "ì—¬ì¹œ", "ì• ì¸", "ì‚¬ê·€", "ì—°ì¸"],
        "ìƒì¼": ["ìƒì¼", "íƒœì–´ë‚œ", "ëª‡ì‚´", "ë‚˜ì´"],
        "í‚¤": ["í‚¤", "ì‹ ì¥", "í¬ê¸°"],
        "ì´ë¦„": ["ì´ë¦„", "ë­ë¼ê³  ë¶ˆëŸ¬", "ëˆ„êµ¬"],
        "ì·¨ë¯¸": ["ì·¨ë¯¸", "ì¢‹ì•„í•˜", "ì¦ê²¨"],
        "ì§ì—…": ["ì§ì—…", "ì¼", "íšŒì‚¬", "í•™êµ"],
    }
    related_tags = []
    question_lower = question.lower()
    for tag_name, tag_keywords in keywords.items():
        if any(kw in question_lower for kw in tag_keywords):
            found_tag, data = search_tag(tag_name)
            if data:
                for item in data[-3:]:
                    related_tags.append(f"[{found_tag}] {item.get('content', '')}")
    return related_tags

# ============ ìë™ íƒœê¹… ì‹œìŠ¤í…œ ============
def detect_important_info(text):
    patterns = {
        "ì—¬ìì¹œêµ¬": [
            r"ì—¬ìì¹œêµ¬.*ì´ë¦„.*[ì€ëŠ”ì´ê°€]?\s*(\S+)",
            r"ì—¬ì¹œ.*ì´ë¦„.*[ì€ëŠ”ì´ê°€]?\s*(\S+)",
            r"ì• ì¸.*ì´ë¦„.*[ì€ëŠ”ì´ê°€]?\s*(\S+)",
            r"ì‚¬ê·€ëŠ”.*ì‚¬ëŒ.*(\S+)",
            r"ì—¬ìì¹œêµ¬ê°€?\s+(\S+)[ì´ì•¼ë¼ê³ ]",
        ],
        "ìƒì¼": [
            r"ë‚´?\s*ìƒì¼.*(\d+ì›”\s*\d+ì¼)",
            r"(\d+ì›”\s*\d+ì¼).*ìƒì¼",
            r"ìƒì¼ì´?\s*(\d{1,2}[ì›”/\-]\d{1,2})",
        ],
        "í‚¤": [
            r"í‚¤ê°€?\s*(\d{2,3})\s*(cm|ì„¼í‹°)?",
            r"(\d{2,3})\s*(cm|ì„¼í‹°).*í‚¤",
            r"ë‚´\s*í‚¤.*(\d{2,3})",
        ],
        "ì´ë¦„": [
            r"ë‚´\s*ì´ë¦„.*[ì€ëŠ”ì´ê°€]?\s*(\S+)",
            r"ë‚˜.*[ì€ëŠ”]\s*(\S+)[ì´ì•¼ë¼ê³ ]",
            r"(\S+)[ì´ë¼ê³ ]?\s*ë¶ˆëŸ¬",
        ],
        "ì·¨ë¯¸": [
            r"ì·¨ë¯¸.*[ì€ëŠ”ì´ê°€]?\s*(\S+)",
            r"(\S+)[ì„ë¥¼ì´ê°€]?\s*ì¢‹ì•„í•´",
            r"(\S+)\s*í•˜ëŠ”\s*ê±°\s*ì¢‹ì•„",
        ],
    }
    for tag_name, regex_list in patterns.items():
        for pattern in regex_list:
            match = re.search(pattern, text)
            if match:
                return {
                    "tag_name": tag_name,
                    "content": text,
                    "extracted": match.group(1) if match.groups() else text
                }
    return None

def process_tag_command(text, recent_conversation):
    text_lower = text.lower().replace(" ", "")
    text_spaced = text.lower()

    if "íƒœê·¸" in text_spaced and ("ëª©ë¡" in text_spaced or "ë­ìˆ" in text_lower or "ì•Œë ¤" in text_spaced and "ìˆ" in text_spaced):
        tags = get_all_tags()
        if tags:
            return f"ì €ì¥ëœ íƒœê·¸: {', '.join(tags)}"
        else:
            return "ì•„ì§ ì €ì¥ëœ íƒœê·¸ê°€ ì—†ì–´ìš”."

    search_patterns = ["íƒœê·¸ì—ë­", "íƒœê·¸ë‚´ìš©", "íƒœê·¸ê²€ìƒ‰", "íƒœê·¸ì—ìˆ", "íƒœê·¸ì•Œë ¤", "íƒœê·¸ì—ì„œì°¾"]
    for pattern in search_patterns:
        if pattern in text_lower:
            for p in ["íƒœê·¸ì—", "íƒœê·¸ë‚´", "íƒœê·¸ê²€", "íƒœê·¸ì•Œ", "íƒœê·¸ì—ì„œ"]:
                if p in text_lower:
                    words = text_spaced.split()
                    for i, w in enumerate(words):
                        if "íƒœê·¸" in w and i > 0:
                            tag_name = words[i-1]
                            found_tag, data = search_tag(tag_name)
                            if data:
                                summaries = [item.get("content", "")[:50] for item in data[-3:]]
                                return f"'{found_tag}' íƒœê·¸ì— {len(data)}ê°œ ì €ì¥ë¨: {'; '.join(summaries)}"
                            elif found_tag:
                                return f"'{found_tag}' íƒœê·¸ëŠ” ìˆì§€ë§Œ ë‚´ìš©ì´ ì—†ì–´ìš”."
                            else:
                                return f"'{tag_name}'ê³¼ ë¹„ìŠ·í•œ íƒœê·¸ë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”. ì €ì¥ëœ íƒœê·¸: {', '.join(get_all_tags())}"
            break

    save_patterns = [
        ("ë¡œíƒœê·¸", "ë¡œ"),
        ("ìœ¼ë¡œíƒœê·¸", "ìœ¼ë¡œ"),
        ("ì—íƒœê·¸", "ì—"),
        ("íƒœê·¸ì—ì €ì¥", "íƒœê·¸ì—"),
        ("íƒœê·¸ì—ì¶”ê°€", "íƒœê·¸ì—"),
        ("íƒœê·¸í•´", "íƒœê·¸"),
    ]

    for pattern, split_word in save_patterns:
        if pattern in text_lower:
            words = text_spaced.split()
            tag_name = None
            for i, word in enumerate(words):
                if "íƒœê·¸" in word:
                    if i > 0 and ("ë¡œ" in words[i-1] or "ì—" in words[i-1]):
                        tag_name = words[i-1].replace("ë¡œ", "").replace("ìœ¼ë¡œ", "").replace("ì—", "")
                    elif "íƒœê·¸ì—" in word or "íƒœê·¸ë¡œ" in word:
                        tag_name = word.replace("íƒœê·¸ì—", "").replace("íƒœê·¸ë¡œ", "").replace("íƒœê·¸", "")
                    elif i > 0:
                        tag_name = words[i-1]
                    break
            if tag_name and len(tag_name) >= 1 and tag_name not in ["ì´ê±°", "ì´ê±¸", "ê²ƒ", "ê±°", "ë¥¼", "ì„"]:
                content = " | ".join([f"{c['role']}: {c['content']}" for c in recent_conversation])
                saved_tag = save_to_tag(tag_name, content)
                if saved_tag:
                    return f"'{saved_tag}' íƒœê·¸ë¡œ ì €ì¥í–ˆì–´ìš”!"
                else:
                    return "íƒœê·¸ ì €ì¥ì— ì‹¤íŒ¨í–ˆì–´ìš”."
            else:
                return "ì–´ë–¤ íƒœê·¸ë¡œ ì €ì¥í• ê¹Œìš”? ì˜ˆ: 'ì—…ë¬´ë¡œ íƒœê·¸í•´ì¤˜' ë˜ëŠ” 'ì—…ë¬´ íƒœê·¸ì— ì €ì¥í•´ì¤˜'"

    return None

wake_variants = [
    "ì˜¤ë¹„ì„œ", "ì˜¤ ë¹„ì„œ", "ì•ˆë…•ë¹„ì„œ", "ì•ˆë…• ë¹„ì„œ", "ì•ˆë‡¨ë¹„ì„œ",
    "ì•ˆë‡¨ì˜¤ë¹„ì„œ", "ì˜¤ë¹—ì–´", "ì˜¤ë¹—ì„œ", "ì–´ë¹„ì„œ", "ì˜¤ë¹„ì¨",
    "ì˜¤ë¹—", "ì˜¤ë¹„", "ì–´ë¹—ì„œ", "ì–´ë¹„ì¨", "ì˜¤ì‚ì„œ", "ì˜¤ì‚ì¨",
    "ì˜¤í”¼ì„œ", "ì˜¤í”¼ì¨", "ì˜µë¹„ì„œ", "ì˜µì„œ", "ì˜¤ë¸Œì„œ",
    "í˜¸ë¹„ì„œ", "í˜¸ ë¹„ì„œ", "í—ˆë¹„ì„œ", "í—¤ë¹„ì„œ",
    "ì˜¤ë¹„ìŠ¤", "ì˜¤ë¹„ì¦ˆ", "ì˜¤ë¹„ìˆ˜", "ì˜¤ë¹„ì‘¤",
    "ë¹„ì„œ", "ë¹„ì„œì•¼", "ì•¼ë¹„ì„œ",
    "ê¹€ë¹„ì„œ", "ê¹€ë¹„ì„", "ê¹€ì§€ì„", "ì´ë¹„ì„œ"
]

def get_access_token():
    url = "https://openapi.vito.ai/v1/authenticate"
    data = {"client_id": CLIENT_ID, "client_secret": CLIENT_SECRET}
    response = requests.post(url, data=data)
    return response.json()["access_token"]

def get_rms(data):
    count = len(data) // 2
    shorts = struct.unpack("%dh" % count, data)
    sum_squares = sum(s ** 2 for s in shorts)
    return math.sqrt(sum_squares / count) if count > 0 else 0

def is_wake_word(text):
    if not text:
        return False
    text_clean = text.lower().replace(" ", "").replace(".", "").replace(",", "")
    wake_variants = [
        "ì˜¤ë¹„ì„œ", "ì˜¤ ë¹„ì„œ", "ì•ˆë…•ë¹„ì„œ", "ì•ˆë…• ë¹„ì„œ", "ì•ˆë‡¨ë¹„ì„œ",
        "ì•ˆë‡¨ì˜¤ë¹„ì„œ", "ì˜¤ë¹—ì–´", "ì˜¤ë¹—ì„œ", "ì–´ë¹„ì„œ", "ì˜¤ë¹„ì¨"
    ]
    for word in wake_variants:
        word_clean = word.replace(" ", "")
        if word_clean in text_clean:
            print(f"âœ… ì •í™• ë§¤ì¹­: {word}")
            return True
    if "ë¹„ì„œ" in text_clean:
        print(f"âœ… 'ë¹„ì„œ' ë§¤ì¹­: {text}")
        return True
    for word in wake_variants:
        word_clean = word.replace(" ", "")
        ratio = SequenceMatcher(None, word_clean, text_clean).ratio()
        if ratio > 0.55:
            print(f"âœ… ìœ ì‚¬ë„ ë§¤ì¹­: {text_clean} â‰ˆ {word} ({ratio:.0%})")
            return True
    return False

def text_to_speech(text):
    print(f"ğŸ”Š ì‘ë‹µ: {text}")
    try:
        client = texttospeech.TextToSpeechClient()
        synthesis_input = texttospeech.SynthesisInput(text=text)
        voice = texttospeech.VoiceSelectionParams(
            language_code="ko-KR",
            name="ko-KR-Wavenet-A",
            ssml_gender=texttospeech.SsmlVoiceGender.FEMALE
        )
        audio_config = texttospeech.AudioConfig(
            audio_encoding=texttospeech.AudioEncoding.MP3
        )
        response = client.synthesize_speech(
            input=synthesis_input, voice=voice, audio_config=audio_config
        )
        with open(OUTPUT_FILE, "wb") as out:
            out.write(response.audio_content)
        subprocess.run(["ffmpeg", "-y", "-i", OUTPUT_FILE, "output.wav"], 
                       stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        subprocess.run(["aplay", "-D", "plughw:2,0", "output.wav"])
    except Exception as e:
        print(f"TTS ì˜¤ë¥˜: {e}, espeakë¡œ ëŒ€ì²´")
        subprocess.run(f'espeak -v ko "{text}" --stdout | aplay -D plughw:2,0', shell=True)

def listen_for_wake_word(token):
    print("\nğŸ‘‚ 'ì˜¤ ë¹„ì„œ'ë¥¼ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘...")
    p = pyaudio.PyAudio()
    stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE,
                    input=True, input_device_index=1, frames_per_buffer=CHUNK)
    frames = []
    recording = False
    silent_chunks = 0
    
    while True:
        data = stream.read(CHUNK, exception_on_overflow=False)
        rms = get_rms(data)
        
        if rms > SILENCE_THRESHOLD:
            if not recording:
                recording = True
                frames = []
            frames.append(data)
            silent_chunks = 0
        elif recording:
            frames.append(data)
            silent_chunks += 1
            if silent_chunks > int(SILENCE_DURATION * RATE / CHUNK):
                stream.stop_stream()
                stream.close()
                p.terminate()
                
                if len(frames) < int(0.5 * RATE / CHUNK):
                    p = pyaudio.PyAudio()
                    stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE,
                                    input=True, input_device_index=1, frames_per_buffer=CHUNK)
                    recording = False
                    frames = []
                    continue
                
                wf = wave.open(WAVE_FILE, 'wb')
                wf.setnchannels(CHANNELS)
                wf.setsampwidth(2)
                wf.setframerate(RATE)
                wf.writeframes(b''.join(frames))
                wf.close()
                
                print("ë…¹ìŒ ì™„ë£Œ, STT í˜¸ì¶œ ì¤‘...")
                text = speech_to_text_stt(token)
                print(f"STT ê²°ê³¼: {text}")
                
                if is_wake_word(text):
                    return True
                else:
                    p = pyaudio.PyAudio()
                    stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE,
                                    input=True, input_device_index=1, frames_per_buffer=CHUNK)
                    recording = False
                    frames = []

def record_command():
    print("ğŸ¤ ë§ì”€í•˜ì„¸ìš”...")
    p = pyaudio.PyAudio()
    stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE,
                    input=True, input_device_index=1, frames_per_buffer=CHUNK)
    frames = []
    silent_chunks = 0
    started = False
    
    while True:
        data = stream.read(CHUNK, exception_on_overflow=False)
        rms = get_rms(data)
        
        if rms > SILENCE_THRESHOLD:
            started = True
            frames.append(data)
            silent_chunks = 0
        elif started:
            frames.append(data)
            silent_chunks += 1
            if silent_chunks > int(SILENCE_DURATION * RATE / CHUNK):
                break
    
    stream.stop_stream()
    stream.close()
    p.terminate()
    
    wf = wave.open(WAVE_FILE, 'wb')
    wf.setnchannels(CHANNELS)
    wf.setsampwidth(2)
    wf.setframerate(RATE)
    wf.writeframes(b''.join(frames))
    wf.close()
    print("âœ… ë…¹ìŒ ì™„ë£Œ!")

def speech_to_text_stt(token):
    url = "https://openapi.vito.ai/v1/transcribe"
    headers = {"Authorization": f"Bearer {token}"}
    with open(WAVE_FILE, 'rb') as f:
        files = {"file": f}
        data = {"config": json.dumps({"use_diarization": False})}
        response = requests.post(url, headers=headers, files=files, data=data)
    
    task_id = response.json()["id"]
    result_url = f"https://openapi.vito.ai/v1/transcribe/{task_id}"
    while True:
        result = requests.get(result_url, headers=headers).json()
        if result["status"] == "completed":
            if result["results"]["utterances"]:
                return result["results"]["utterances"][0]["msg"]
            return None
        elif result["status"] == "failed":
            return None
        time.sleep(0.1)

def classify_question(question):
    print("ğŸ§  ì§ˆë¬¸ ë¶„ë¥˜ ì¤‘...")
    client = anthropic.Anthropic(api_key=CLAUDE_API_KEY)
    message = client.messages.create(
        model="claude-sonnet-4-20250514",
        max_tokens=10,
        messages=[{"role": "user", "content": f"ì§ˆë¬¸ì„ ë¶„ë¥˜í•´. ì‹¤ì‹œê°„ ì •ë³´(ë‚ ì”¨,ë‰´ìŠ¤,ì£¼ê°€,ì‹œê°„,ê²€ìƒ‰)ë©´ gemini, ì•„ë‹ˆë©´ claude. í•œ ë‹¨ì–´ë§Œ ë‹µí•´.\n\nì§ˆë¬¸: {question}\në‹µ:"}]
    )
    result = message.content[0].text.strip().lower()
    return "gemini" if "gemini" in result else "claude"

def ask_gemini(question):
    global conversation_history
    print("ğŸŒ Gemini ê²€ìƒ‰ ì¤‘...")

    conversation_history.append({"role": "user", "content": question})
    save_to_supabase("user", question)
    add_to_mem0(question)

    model = genai.GenerativeModel('gemini-2.0-flash')
    response = model.generate_content(f"ì¹œì ˆí•œ AI ë¹„ì„œë¡œì„œ ì§§ê²Œ í•œêµ­ì–´ë¡œ ë‹µí•´. 2-3ë¬¸ì¥.\n\nì§ˆë¬¸: {question}")
    result = response.text

    conversation_history.append({"role": "assistant", "content": result})
    save_to_supabase("assistant", result)
    save_history(conversation_history)

    return result

def ask_claude(question):
    global conversation_history
    print("ğŸ¤– Claude ìƒê° ì¤‘...")

    conversation_history.append({"role": "user", "content": question})
    save_to_supabase("user", question)
    add_to_mem0(question)

    if len(conversation_history) > MAX_HISTORY * 2:
        conversation_history = conversation_history[-MAX_HISTORY * 2:]

    mem0_memories = search_mem0(question)
    tag_context = get_tag_context(question)
    
    system_prompt = "ì¹œì ˆí•œ AI ìŒì„± ë¹„ì„œ 'ì˜¤ ë¹„ì„œ'. ì§§ê³  ìì—°ìŠ¤ëŸ½ê²Œ í•œêµ­ì–´ë¡œ 2-3ë¬¸ì¥ ë‹µë³€. ì´ì „ ëŒ€í™” ë§¥ë½ì„ ê¸°ì–µí•´ì„œ ë‹µë³€."

    if mem0_memories:
        mem0_info = "\n".join([f"- {m}" for m in mem0_memories])
        system_prompt += f"\n\n[ì‚¬ìš©ìì— ëŒ€í•´ ê¸°ì–µí•˜ëŠ” ì •ë³´]\n{mem0_info}"
        print(f"ğŸ§  Mem0 ê¸°ì–µ {len(mem0_memories)}ê°œ ì°¸ì¡°")

    if tag_context:
        tag_info = "\n".join(tag_context)
        system_prompt += f"\n\n[ì‚¬ìš©ìê°€ ì €ì¥í•œ íƒœê·¸ ì •ë³´]\n{tag_info}"
        print(f"ğŸ“Œ íƒœê·¸ ì»¨í…ìŠ¤íŠ¸ {len(tag_context)}ê°œ ì°¸ì¡°")

    client = anthropic.Anthropic(api_key=CLAUDE_API_KEY)
    message = client.messages.create(
        model="claude-sonnet-4-20250514",
        max_tokens=200,
        messages=conversation_history,
        system=system_prompt
    )

    response = message.content[0].text

    conversation_history.append({"role": "assistant", "content": response})
    save_to_supabase("assistant", response)
    save_history(conversation_history)

    return response

def main():
    global pending_tag_info
    print("=" * 50)
    print("ğŸ¤– AI ìŒì„± ë¹„ì„œ - ì˜¤ ë¹„ì„œ")
    print("ğŸ§  Mem0 ìŠ¤ë§ˆíŠ¸ ê¸°ì–µ í™œì„±í™”!")
    print("=" * 50)
    print("ğŸ“Œ 'ì˜¤ ë¹„ì„œ'ë¼ê³  ë¶ˆëŸ¬ì£¼ì„¸ìš”!")
    print("=" * 50)

    token = get_access_token()
    print("âœ… ë¦¬í„´ì œë¡œ ì¸ì¦ ì™„ë£Œ!")

    while True:
        try:
            if listen_for_wake_word(token):
                text_to_speech("ë„¤, ë§ì”€í•˜ì„¸ìš”")

                while True:
                    time.sleep(0.3)
                    record_command()
                    print("ğŸ”„ ìŒì„± ì¸ì‹ ì¤‘...")
                    question = speech_to_text_stt(token)

                    if question:
                        if any(word in question for word in ["ì¢…ë£Œ", "ê·¸ë§Œ", "ë", "ì˜ê°€"]):
                            text_to_speech("ë„¤, ë‹¤ìŒì— ë˜ ë¶ˆëŸ¬ì£¼ì„¸ìš”!")
                            pending_tag_info = None
                            break

                        print(f"\nğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸: {question}")

                        if pending_tag_info:
                            if any(word in question for word in ["ì‘", "ë„¤", "ì¢‹ì•„", "ê·¸ë˜", "í•´ì¤˜", "ì €ì¥", "ì˜ˆ"]):
                                saved = save_to_tag(pending_tag_info["tag_name"], pending_tag_info["content"])
                                if saved:
                                    text_to_speech(f"'{saved}' íƒœê·¸ì— ì €ì¥í–ˆì–´ìš”!")
                                else:
                                    text_to_speech("ì €ì¥ì— ì‹¤íŒ¨í–ˆì–´ìš”.")
                                pending_tag_info = None
                                continue
                            elif any(word in question for word in ["ì•„ë‹ˆ", "ì‹«ì–´", "ëì–´", "ê´œì°®ì•„", "ì•ˆí•´"]):
                                text_to_speech("ì•Œê² ì–´ìš”, ì €ì¥í•˜ì§€ ì•Šì„ê²Œìš”.")
                                pending_tag_info = None
                                continue
                            else:
                                pending_tag_info = None

                        tag_response = process_tag_command(question, conversation_history[-4:] if len(conversation_history) >= 4 else conversation_history)
                        if tag_response:
                            text_to_speech(tag_response)
                            continue

                        ai_choice = classify_question(question)
                        print(f"ğŸ¯ ì„ íƒëœ AI: {ai_choice}")

                        if ai_choice == "gemini":
                            response = ask_gemini(question)
                        else:
                            response = ask_claude(question)

                        text_to_speech(response)

                        detected = detect_important_info(question)
                        if detected:
                            pending_tag_info = detected
                            tag_name = detected["tag_name"]
                            text_to_speech(f"'{tag_name}' íƒœê·¸ì— ì €ì¥í• ê¹Œìš”?")
                            print(f"ğŸ·ï¸ ìë™ íƒœê¹… ê°ì§€: {tag_name} - {detected['extracted']}")

                    else:
                        print("(ì¡°ìš©í•¨ ê°ì§€, ëŒ€í™” ì¢…ë£Œ)")
                        pending_tag_info = None
                        break

        except KeyboardInterrupt:
            print("\nğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤!")
            break
        except Exception as e:
            print(f"ì˜¤ë¥˜: {e}")
            continue

if __name__ == "__main__":
    main()
